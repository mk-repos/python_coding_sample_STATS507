{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Multilayer Perceptrons\n",
    "\n",
    "**name:** XX\n",
    "\n",
    "**email:** XX@umich.edu\n",
    "\n",
    "**I discussed XX with XX.** (List *everyone* with whom you discussed any of the homework problems, excluding only the GSIs and the course instructor. If you did not discuss the homework with anyone else, write \"I did not discuss this homework with anyone.\" Even if you discuss questions with others, you may not copy other students' solutions: the code you submit must be yours alone. All work is checked with the [MOSS plagiarism detector](https://theory.stanford.edu/~aiken/moss/).)\n",
    "\n",
    "**This homework assignment took me XX hours in total to complete.** (Please help us to gauge the difficulty of the assignment.)\n",
    "\n",
    "### Submission Instructions\n",
    "Your homework solutions should be written entirely in this Jupyter notebook file. Once it contains your solutions, you should submit this notebook through Canvas. Before submitting, please make sure make sure __Cells->Run__ executes without errors; errors in your code cause problems for our auto-grader. Thus, even though we frequently ask you to check for errors in your functions, you should not include in your submission any examples of your functions actually raising those errors.\n",
    "\n",
    "### Pillow\n",
    "Note that Python's Imaging Library (PIL) can be installed via\n",
    "\n",
    "    conda install pillow\n",
    "    \n",
    "or\n",
    "\n",
    "    pip install pillow\n",
    "\n",
    "\n",
    "### Credits\n",
    "This homework assignment is based on a homework assignment written by Sebastian Raschka (sraschka@wisc.edu)\n",
    "The dataset is from him too. Please do not distribute this modified version of his work.\n",
    "\n",
    "### Supplemental Data Files\n",
    "Run the following code to download the supplemental files you will need to complete this homework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from os import path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "url = \"https://regier.stat.lsa.umich.edu/stats507/\"\n",
    "fn = \"hw7data.zip\"\n",
    "if not path.exists(fn):\n",
    "    data = request.urlopen(url + fn).read()\n",
    "    with open(fn, 'wb') as fhand:\n",
    "        fhand.write(data)\n",
    "    with ZipFile(fn, 'r') as zipObj:\n",
    "        zipObj.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding style\n",
    "Please follow the [PEP8 guidelines](https://www.python.org/dev/peps/pep-0008/). The `pycodestyle_magic` package will remind you if you are not. To install it, run\n",
    "```\n",
    "pip install flake8 pycodestyle_magic\n",
    "```\n",
    "Once it is installed the following two Jupyter directives will enable syntax checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (20 points)\n",
    "\n",
    "Modify the Multilayer Perceptron implementation below to achieve a better performance. In particular,\n",
    "- Your Validation and Test set accuracies should be >= 92%\n",
    "- Answer the questions at the bottom of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please read and execute this notebook first to make sure everything works correctly. Then, make any changes to the architecture, i.e., you can change\n",
    "\n",
    "- the number of layers\n",
    "- the activation function(s) (logistic sigmoid, tanh, relu, leaky relu, ...)\n",
    "- the learning rate\n",
    "- the number of hidden layers\n",
    "- the number of units in the hidden layer(s)\n",
    "- the number of epochs\n",
    "- the minibatch size\n",
    "\n",
    "However,\n",
    "\n",
    "- don't change the weight initialization\n",
    "- don't change the random seed\n",
    "- don't change the optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to change anything here!\n",
    "# If there is a GPU available, it will use it,\n",
    "# otherwise, it will use the CPU\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# NOTE: I actually noticed that this code runs faster on the CPU than on the\n",
    "# GPU, because the dataset is so small. However, you are encouraged to try\n",
    "# out training on a GPU, e.g., via Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 3 classes:\n",
    "- Drawings of \"birds\" (class 0)\n",
    "- Drawings of \"pizzas\" (class 1)\n",
    "- Drawings of \"screwdrivers\" (class 2)\n",
    "\n",
    "(The dataset is based on Google Quickdraw: I wrote a script to fetch the images from the database here: https://quickdraw.withgoogle.com/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is very small on purpose so that the training should be relatively fast (but this wouldn't be an ideal DL dataset because of its small size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "print('Class distribution Train', np.bincount(df_train['Class Label'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are 28x28 dimensional (grayscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "image_paths = sorted(glob.glob('png-files/*.png'))\n",
    "for i in (12, 25, 30000, 30001, 60000, 60005):\n",
    "    im_path = image_paths[i]\n",
    "    print(im_path)\n",
    "    im = Image.open(im_path)\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- The only thing you should change in this section during experimenting is the batch size\n",
    "- However, it is not required to make changes to the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickdrawDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading Quickdraw images\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = df['Filename'].values\n",
    "        self.y = df['Class Label'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that transforms.ToTensor()\n",
    "# already divides pixels by 255. internally\n",
    "custom_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "train_dataset = QuickdrawDataset(csv_path='train.csv',\n",
    "                                 img_dir='png-files/',\n",
    "                                 transform=custom_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=128,  # CHANGE IF YOU LIKE\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "\n",
    "\n",
    "valid_dataset = QuickdrawDataset(csv_path='valid.csv',\n",
    "                                 img_dir='png-files/',\n",
    "                                 transform=custom_transform)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4)\n",
    "\n",
    "test_dataset = QuickdrawDataset(csv_path='test.csv',\n",
    "                                img_dir='png-files/',\n",
    "                                transform=custom_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=128,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below just checks if the dataset can be loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "\n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        print('break minibatch for-loop')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an error, make sure the `png-files` folder is unzipped and it the same directory as this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains the multi-layer perceptron model. This is the main section where you want to make changes to the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden_1, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # ADD ADDITIONAL LAYERS BELOW IF YOU LIKE\n",
    "        self.linear_1 = torch.nn.Linear(num_features, num_hidden_1)\n",
    "        self.linear_out = torch.nn.Linear(num_hidden_1, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # MAKE SURE YOU CONNECT THE LAYERS PROPERLY IF YOU CHANGED\n",
    "        # ANYTHNG IN THE __init__ METHOD ABOVE\n",
    "        out = self.linear_1(x)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        logits = self.linear_out(out)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "# Model Initialization\n",
    "\n",
    "\n",
    "# the random seed makes sure that the random weight initialization\n",
    "# in the model is always the same.\n",
    "# In practice, some weights don't work well, and we may also want\n",
    "# to try different random seeds. In this homework, this is not\n",
    "# necessary.\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# IF YOU CHANGED THE ARCHITECTURE ABOVE, MAKE SURE YOU\n",
    "# ACCOUNT FOR IT VIA THE PARAMETERS BELOW. I.e., if you\n",
    "# added a second hidden layer, you may want to add a\n",
    "# hidden_2 parameter here. Also you may want to play\n",
    "# with the number of hidden units.\n",
    "model = MLP(num_features=28*28,\n",
    "            num_hidden_1=50,\n",
    "            num_classes=3)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "\n",
    "# For this homework, do not change the optimizer. However, you\n",
    "# likely want to experiment with the learning rate!\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "\n",
    "# PLEASE DON'T CHANGE THE compute_epoch_loss\n",
    "# and the compute accuracy functions\n",
    "\n",
    "def compute_epoch_loss(model, data_loader):\n",
    "    curr_loss, num_examples = 0., 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.view(-1, 28*28).to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            logits, probas = model(features)\n",
    "            loss = F.cross_entropy(logits, targets, reduction='sum')\n",
    "            num_examples += targets.size(0)\n",
    "            curr_loss += loss\n",
    "\n",
    "        curr_loss = curr_loss / num_examples\n",
    "        return curr_loss\n",
    "\n",
    "\n",
    "def compute_accuracy(model, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.view(-1, 28*28).to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            logits, probas = model.forward(features)\n",
    "            predicted_labels = torch.argmax(probas, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "        return correct_pred.float()/num_examples * 100\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "minibatch_cost = []\n",
    "epoch_cost = []\n",
    "\n",
    "# NO NEED TO CHANGE ANYTHING BELOW. HOWEVER, YOU CAN CHANGE\n",
    "# THE NUMBER OF EPOCHS IF YOU LIKE\n",
    "\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        features = features.view(-1, 28*28).to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        # FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        minibatch_cost.append(cost)\n",
    "\n",
    "        # UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "\n",
    "        # LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f'\n",
    "                  % (epoch+1, NUM_EPOCHS, batch_idx,\n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    model.eval()\n",
    "    cost = compute_epoch_loss(model, train_loader)\n",
    "    epoch_cost.append(cost)\n",
    "\n",
    "    train_accuracy = compute_accuracy(model, train_loader)\n",
    "    valid_accuracy = compute_accuracy(model, valid_loader)\n",
    "\n",
    "    print('Epoch: %03d/%03d Train Cost: %.4f' % (\n",
    "            epoch+1, NUM_EPOCHS, cost))\n",
    "    print('Train Accuracy: %.3f | Validation Accuracy: %.3f'\n",
    "          % (train_accuracy, valid_accuracy))\n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation (No Need To Change Any Code in This Section!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(minibatch_cost)), minibatch_cost)\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Minibatch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(epoch_cost)), epoch_cost)\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy: %.2f' % compute_accuracy(model, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions (YOUR ANSWERS REQUIRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) What is your training, validation, and test accuracy (paste your numbers from above)? Also, do you notice any overfitting? If yes, why do you think your model is overfitting, and what would be a simple technique to reduce overfitting?**\n",
    "\n",
    "[Your answers here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) What architectual changes did you make to improve the performance?**\n",
    "\n",
    "[Briefly list the changes here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Assuming you increased the accuracy by 3%, how many more correct predictions did the improved model make in the test set?**\n",
    "\n",
    "[Provide a short calculation and number (i.e., provide a count of images)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
