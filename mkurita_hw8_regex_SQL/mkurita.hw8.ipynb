{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8: Regexes and Structured Data (35 points)\n",
    "name: Moeki Kurita\n",
    "\n",
    "email: mkurita@umich.edu\n",
    "\n",
    "I did not discuss this homework with anyone.\n",
    "\n",
    "This homework assignment took me 10 hours in total to complete. (Please help us to gauge the difficulty of the assignment.)\n",
    "\n",
    "### Submission Instructions\n",
    "Your homework solutions should be written entirely in this Jupyter notebook file. Once it contains your solutions, you should submit this notebook through Canvas. Before submitting, please make sure make sure __Cells->Run__ executes without errors; errors in your code cause problems for our auto-grader. Thus, even though we may ask you to check for errors in your functions, you should not include in your submission any examples of your functions actually raising those errors.\n",
    "\n",
    "### Coding style\n",
    "Please follow the [PEP8 guidelines](https://www.python.org/dev/peps/pep-0008/). The `pycodestyle_magic` package will remind you if you are not. To install it, run\n",
    "```\n",
    "pip install flake8 pycodestyle_magic\n",
    "```\n",
    "Once it is installed the following two Jupyter directives will enable syntax checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import urllib\n",
    "from os import path\n",
    "from zipfile import ZipFile\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "\n",
    "url = \"https://regier.stat.lsa.umich.edu/stats507/\"\n",
    "fn = \"hw8data.zip\"\n",
    "if not path.exists(fn):\n",
    "    data = request.urlopen(url + fn).read()\n",
    "    with open(fn, 'wb') as fhand:\n",
    "        fhand.write(data)\n",
    "    with ZipFile(fn, 'r') as zipObj:\n",
    "        zipObj.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Regular Expressions: Warmup (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you'll get practice with basic regular expressions. Pay particular attention to edge cases such as the empty string\n",
    "and single-character strings when writing your regexes. At the URL http://www.greenteapress.com/thinkpython/code/words.txt is a list of about 100,000 English words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use __urllib__ to open the URL and read the file, and produce a list of ASCII strings so that each line of the file corresponds to an element of the list. You will likely need to convert the raw bytes read from the webpage to ASCII characters, for which you should see the documentation for the string methods __encode__ and __decode__. How many words are in the file?\n",
    "\n",
    "Answer:\n",
    "\n",
    "113809 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113809\n"
     ]
    }
   ],
   "source": [
    "response = request.urlopen(\n",
    "    'http://www.greenteapress.com/thinkpython/code/words.txt')\n",
    "file = response.read()\n",
    "words = file.decode(encoding='ascii').split()\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. It is a good habit to always look at your data to check that it makes sense. Have a look at the words in the list. Does anything jump out at you? __Note:__ I am not requiring you to do anything specific, here. Just look at the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aah', 'aahed', 'aahing', 'aahs', 'aal', 'aalii', 'aaliis', 'aals', 'aardvark']\n",
      "['zymogene', 'zymogenes', 'zymogens', 'zymologies', 'zymology', 'zymoses', 'zymosis', 'zymotic', 'zymurgies', 'zymurgy']\n",
      "21\n",
      "2\n",
      "['counterdemonstrations', 'hyperaggressivenesses', 'microminiaturizations']\n",
      "['aa', 'ad', 'ae', 'ah', 'ai', 'am', 'an', 'ar', 'as', 'at', 'aw', 'ay', 'ba', 'be', 'bi', 'bo', 'by', 'da', 'de', 'do', 'ef', 'eh', 'el', 'em', 'en', 'er', 'es', 'et', 'ex', 'fa', 'go', 'ha', 'he', 'hi', 'ho', 'id', 'if', 'in', 'is', 'it', 'jo', 'ka', 'la', 'li', 'lo', 'ma', 'me', 'mi', 'mu', 'my', 'na', 'no', 'nu', 'od', 'oe', 'of', 'oh', 'om', 'on', 'op', 'or', 'os', 'ow', 'ox', 'oy', 'pa', 'pe', 'pi', 're', 'sh', 'si', 'so', 'ta', 'ti', 'to', 'un', 'up', 'us', 'ut', 'we', 'wo', 'xi', 'xu', 'ya', 'ye']\n"
     ]
    }
   ],
   "source": [
    "# The list seems sorted\n",
    "print(words[:10])\n",
    "print(words[-10:])\n",
    "# The maximum & minimum length of words\n",
    "print(max([len(word) for word in words]))\n",
    "print(min([len(word) for word in words]))\n",
    "# Some example of long & short words\n",
    "print([word for word in words if len(word) > 20])\n",
    "print([word for word in words if len(word) < 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a regular expression that matches any string containing exactly three consecutive vowels. Compile this regular expression, and assign it to a variable called `three_consecutive_vowels`. Use this regex to determine how many words from the list contain exactly three consecutive vowels. For the purposes of this __specific__ subproblem, the vowels are __a, e, i, o, u__. All other letters are consonants. Produce a list of all such words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1326"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_consecutive_vowels = re.compile(r'([^aeiou]+|^)[aeiou]{3}([^aeiou]+|$)')\n",
    "# test = ['aa', 'aahaaa', 'aahed', 'aahing', 'aahs',\n",
    "#        'aal', 'aalaai', 'aaaaliiis', 'aals', 'aardvark']\n",
    "lst_three_vowels = [word for word in words\n",
    "                    if re.search(three_consecutive_vowels, word)]\n",
    "len(lst_three_vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(three_consecutive_vowels.match(\"aei\").group(0) == 'aei')\n",
    "print(three_consecutive_vowels.match(\"uiuu\") is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a regular expression that matches any string that contains no instances of the letter e. Compile this regular expression, and assign it to a variable called `gadsby`. (__Gadsby__ is the title of an English novel written in the 1930s that contains __almost__ no instances of the letter e). How many words in the list do not contain the letter e?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37641\n"
     ]
    }
   ],
   "source": [
    "gadsby = re.compile(r'^[^e]*$')\n",
    "lst_gadsby = [word for word in words if re.search(gadsby, word)]\n",
    "print(len(lst_gadsby))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(gadsby.match(\"stats\").group(0) == 'stats')\n",
    "print(gadsby.match(\"state\") is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a regular expression that matches any string that begins and ends with a consonant and has no consonants in between. For the purposes of this __specific__ subproblem, y is neither consonant nor vowel,so consonants are the 20 letters that are not one of __a, e, i, o, u, y__ and vowels are __a, e, i, o, u__. The words need not begin and end with the _same_ consonant, so _door_ is a valid match. Compile this regular expression, and assign it to a variable called `consonant_consonant`. How many words begin and end with a consonant with no consonants in between?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230\n"
     ]
    }
   ],
   "source": [
    "consonant_consonant = re.compile(r'^[^aeiouy][aeiouy]*[^aeiouy]$')\n",
    "lst_consonant = [word for word in words\n",
    "                 if re.search(consonant_consonant, word)]\n",
    "print(len(lst_consonant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(consonant_consonant.match(\"door\").group(0) == 'door')\n",
    "print(consonant_consonant.match(\"stats\") is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a regular expression that matches any string whose last two characters are the first two characters in reverse order. So, for example, your regex should match _repeater_ and _stats_, but not _neoprene_. Compile this regular expression and assign it to a variable called `bookends`. How many words in the list have this property?\n",
    "__Hint:__ Be careful of the cases in which the word is length less or equal to 3. You may handle the case of a single character (e.g., _a_), as you like, but please give an explanation for your choice.\n",
    "\n",
    "I include all the words with a single character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886\n"
     ]
    }
   ],
   "source": [
    "bookends = re.compile(r'^(.)(.).*\\2\\1$|^(.).\\3$|^(.)\\4$|^.$')\n",
    "# test = ['aa', 'aaahaaaa', 'aahed', 'aahing', 'kpk', 'ppp', 'kaa', 'k', 'ke']\n",
    "lst_bookends = [word for word in words\n",
    "                if re.search(bookends, word)]\n",
    "print(len(lst_bookends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(bookends.match(\"repeater\").group(0) == 'repeater')\n",
    "print(bookends.match(\"neoprene\") is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Exploring Internet Traffic with Regexes (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you'll get a taste of a more realistic application of regular expressions. The file __SkypeIRC.txt__ contains data generated by web traffic associated with Skype and IRC, captured using the Wireshark program, a common tool for analyzing web traffic. The original data file can be found on the Wireshark wiki, https://wiki.wireshark.org/SampleCaptures, but please use the file provided on my website for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Each line of `SkypeIRC.txt` corresponds to a single packet sent over the internet. How many packets are in this file? Save the answer in a variable `n_packets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263\n"
     ]
    }
   ],
   "source": [
    "with open('SkypeIRC.txt', 'r', encoding='utf-8') as f_obj:\n",
    "    lst_packets = f_obj.readlines()\n",
    "\n",
    "n_packets = len(lst_packets)\n",
    "print(n_packets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use regular expressions to extract all the IP addresses from the file and collect them in a Python list. An IP address consists of four numbers, which are displayed as __A.B.C.D__ where __A, B, C__ and __D__ are each numbers between 0 and 255 inclusive. How many unique IP addresses appear in the data set? Save the answer in a variable `ip_addresses`. __Note:__ There are a few pieces of text in the file that _look_ like IP addresses but aren't (e.g., they are of the form A.B.C.D, but one or more of A, B, C and D are outside the range 0 to 255). You should try to craft a regex that matches as few of these as you can, but of course it will not be possible to avoid certain edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368\n"
     ]
    }
   ],
   "source": [
    "ip_regex = re.compile(r'([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.'\n",
    "                      r'([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.'\n",
    "                      r'([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.'\n",
    "                      r'([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\D')\n",
    "lst_ips = []\n",
    "for line in lst_packets:\n",
    "    found_ips = re.findall(ip_regex, line)\n",
    "    for tpl in found_ips:\n",
    "        lst_ips.append(\".\".join(tpl))\n",
    "\n",
    "set_ips = set(lst_ips)\n",
    "ip_addresses = len(set_ips)\n",
    "print(ip_addresses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function called `get_packets_by_regex` that takes a single string as its argument and returns a list of all the lines from the input file that match the input string interpreted as a regular expression. So, for example, `get_packets_by_regex(r'comcast')` will return all lines from the file containing the string _'comcast'_. Your function should check that the input is a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_packets_by_regex(s):\n",
    "    if not isinstance(s, str):\n",
    "        raise TypeError('The argument must be a string')\n",
    "    else:\n",
    "        regex = re.compile(s)\n",
    "        return list(filter(regex.search, lst_packets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_packets_by_regex(r'114.214.204.212')) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The second piece of text (i.e., non-whitespace) on each line is a time stamp, counting the time (in seconds) since the beginning of the traffic recording. Using _matplotlib_, create a plot displaying how many packets appeared in each second of the recording. A histogram or line plot is the most obvious way to do this, but you should feel free to use a more creative way of displaying this information if you wish to do so. Save your plot as a PDF, in a file called _timestamps.pdf_. This file does not need to be including in your submission. __Note:__ in case it wasn't obvious, there is no need to use a regular expression for this subproblem if you do not want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_regex = re.compile(r'\\d+\\.\\d{6}')\n",
    "\n",
    "lst_times = []\n",
    "for line in lst_packets:\n",
    "    found_times = re.findall(time_regex, line)\n",
    "    for tpl in found_times:\n",
    "        lst_times.append(\"\".join(tpl))\n",
    "arr_times = np.array(lst_times, dtype=float)\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(10, 10))\n",
    "plt.hist(arr_times, bins=int(arr_times[-1]))\n",
    "plt.xlabel('Seconds')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('The Number of Packets Appeared')\n",
    "plt.show()\n",
    "fig1.savefig('timestamps.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Retrieving Data from the Web (10 points)\n",
    "In this problem, we'll scrape data from Wikipedia using __BeautifulSoup__. Documentation for BeauitfulSoup can be found at https://www.crummy.com/software/BeautifulSoup/bs4/doc/. As mentioned in lecture, there is another package, called __requests__, which is becoming quite popular, which you are welcome to use for this problem instead, if you wish. Documentation for the `requests` package can be found at https://requests.readthedocs.io/en/master/ .\n",
    "\n",
    "Suppose you are trying to choose a city to vacation in. A major factor in your decision is weather. Conveniently, lots of weather information is present in the Wikipedia articles for most world cities. Your job in this problem is to use __BeautifulSoup__ to retrieve weather information from Wikipedia articles. We should note that in practice, such information is typically more easily obtained from, for example, the National Oceanic and Atmospheric Administration (NOAA), in the case of cities in the United States, and from analogous organizations in other countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Look at a few Wikipedia pages corresponding to cities. For example:\n",
    " - https://en.wikipedia.org/wiki/Ann_Arbor,_Michigan\n",
    " - https://en.wikipedia.org/wiki/Buenos_Aires\n",
    " - https://en.wikipedia.org/wiki/Harbin\n",
    "\n",
    " Note that most city pages include a table titled something like \"Climate data for [Cityname] (normals YYYY-YYYY, extremes YYYY-YYYY)\". Find a Wikipedia page for a city that includes such a table (such as one of the three above). In your jupyter notebook, open the URL and read the HTML using either __urllib__ or __requests__, and parse it with __BeautifulSoup__ using the standard parser, __html.parser__. Have a look at the parsed HTML and find the climate data table, which will have the tag __table__ and will contain a child tag __th__ containing a string similar to\n",
    "\n",
    " Climate data for [Cityname] (normals YYYY-YYYY, extremes YYYY-YYYY)}.\n",
    "\n",
    " Find the node in the __BeautifulSoup__ object corresponding to this table. Describe the structure of this node of the tree (e.g., how many children does the table have, what are their tags, etc. A sentence or two is fine, here). You may want to learn a bit about the structure of HTML tables by looking at the resources available on these websites:\n",
    " - https://developer.mozilla.org/en-US/docs/Web/HTML/Element/table\n",
    " - https://www.w3schools.com/html/html_tables.asp\n",
    " - https://www.w3.org/TR/html401/struct/tables.html\n",
    "\n",
    "Answer:\n",
    "\n",
    "We find the node of this table as follows. This table has 1 `tbody`, and it contains 12 rows defined with the `<tr>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct child : ['tbody']\n",
      "Tags under tbody: ['tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr']\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://en.wikipedia.org/wiki/Ann_Arbor,_Michigan')\n",
    "parsed = BeautifulSoup(response.text, 'html.parser')\n",
    "tbl_climate = parsed.find('table', class_='wikitable collapsible')\n",
    "print('Direct child :',\n",
    "      [child.name for child in tbl_climate.children if child != '\\n'])\n",
    "print('Tags under tbody:',\n",
    "      [child.name for child in tbl_climate.tbody.children if child != '\\n'])\n",
    "# parsed.th.descendants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function `retrieve_climate_table` that takes as its only argument a Wikipedia URL, and returns the __BeautifulSoup__ object corresponding to the climate data table (if it exists in the page) and returns __None__ if no such table exists on the page. You should check that the URL is retrieved successfully, and raise an error if __urllib2__ fails to successfully read the website. You may notice that some city pages include more than one climate data table or several nested tables (see, for example, https://en.wikipedia.org/wiki/Los_Angeles). In this case, your function may arbitrarily choose one of the tables to return as a __BeautifulSoup__ object. __Note:__ a good way to check for edge cases is to test your script on the Wikipedia pages for a few of your favorite cities. The pages for Los Angeles, Hyderabad and Boston will give good examples of edge cases that you should be able to handle, but note that these are by no means exhaustive of all the possible edge cases. __Hint:__ make use of the __contents__ attribute of the __BeautifulSoup__ objects and the ability to change the elements of the contents list to Unicode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_climate_table(url):\n",
    "    try:\n",
    "        response = request.urlopen(url)\n",
    "    except urllib.error.URLError:\n",
    "        raise urllib.error.URLError('URL does not seem valid')\n",
    "    else:\n",
    "        parsed = BeautifulSoup(response, 'html.parser')\n",
    "        tbl_climate = parsed.find('table', class_='wikitable collapsible')\n",
    "        if not tbl_climate:\n",
    "            return None\n",
    "        else:\n",
    "            return tbl_climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking edge cases\n",
    "# urls = ['https://en.wikipedia.org/wiki/Hyderabad',\n",
    "#         'https://en.wikipedia.org/wiki/Los_Angeles',\n",
    "#         'https://en.wikipedia.org/wiki/Boston']\n",
    "# tbl_climate1 = retrieve_climate_table(urls[-1])\n",
    "# print(tbl_climate1)\n",
    "# print('Direct child :',\n",
    "#       [child.name for child in tbl_climate1.children if child != '\\n'])\n",
    "# print('Tags under tbody:',\n",
    "#       [child.name for child in tbl_climate1.tbody.children if child != '\\n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. As you look at some of the climate data tables, you may notice that different cities' tables contain different information. For example, not all cities include snowfall data. Write a function `list_climate_table_row_names` that takes as its only argument a Wikipedia URL and returns a list of the row names of the climate data table, or returns __None__ if no such table exists. The list returned by your function should, ideally, consist solely of Python strings (either Unicode or ASCII), and should not include any __BeautifulSoup__ objects or HTML (__Hint:__ see the __BeautifulSoup__ method `get_text()`). The list returned by your script should _not_ include an entry corresponding to the __Climate data for...__ row in the table. __Second hint:__ you are looking for HTML table header (__th__) objects. The HTML attribute `scope` is your friend here, because in the context of an HTML table it tells you when a `th` tag is the header of a row or a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_climate_table_row_names(url):\n",
    "    tbl_climate = retrieve_climate_table(url)\n",
    "    if not tbl_climate:\n",
    "        return None\n",
    "    else:\n",
    "        rows = tbl_climate.find_all('th', scope='row')\n",
    "        return [row.get_text().strip() for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases\n",
    "# urls = ['https://en.wikipedia.org/wiki/Hyderabad',\n",
    "#         'https://en.wikipedia.org/wiki/Los_Angeles',\n",
    "#         'https://en.wikipedia.org/wiki/Boston']\n",
    "# print(list_climate_table_row_names(urls[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The next natural step would be to write a function that takes a URL and a row name and retrieves the data from that row of the climate data table (if the table exists and has that row name). Doing this would require some complicated string wrangling to get right, so I'll spare you the trouble. Instead, please __briefly__ describe either in pseudo code or in plain English how you would accomplish this, using the two functions you wrote above and the tools available to you in the __BeautifulSoup__ package. __Note:__ just to be clear, you __do not__ have to write any Python code for this last step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "**Step1** By using `retrieve_climate_table()`, we find the node corresponding to the climate table. Then by using `list_climate_table_row_names()`, we get the list of row names. We can find the node corresponding to the row we want to retrieve the data from by using `find('th', text=*rowname*)`.\n",
    "\n",
    "**Step2** We notice that each row has children defined as `<td>data</td>`. We just need to write a function very similar to `list_climate_table_row_names()`, which applies `find_all('td')` to the node corresponding to the row we want to extract, and returns data as a list of strings using `get_text()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Relational Databases and SQL (10 points)\n",
    "In this problem, you'll interact with a toy SQL database using Python's built-in __sqlite3__ package. Documentation can be found at https://docs.python.org/3/library/sqlite3.html. For this problem, we'll use a popular toy SQLite database, called Chinook, which represents a digital music collection. See the documentation at\n",
    " \n",
    " https://github.com/lerocha/chinook-database/blob/master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite\n",
    "\n",
    " for a more detailed explanation. We'll use the __.sqlite__ file __Chinook\\_Sqlite.sqlite__, which you downloaded above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the database using the Python __sqlite3__ package. How many tables are in the database? Save the answer in the variable `n_tables`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('Chinook_Sqlite.sqlite')\n",
    "c = conn.cursor()\n",
    "lst_tbl = [r for r\n",
    "           in c.execute('SELECT * FROM sqlite_master WHERE type = \"table\"')]\n",
    "n_tables = len(lst_tbl)\n",
    "print(n_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are the names of the tables in the database? Save the answer as a list of strings, `table_names`. __Note:__ you should write Python __sqlite3__ code to answer this; don't just look up the answer in the documentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    }
   ],
   "source": [
    "table_names = [table[0] for table in c.execute(\n",
    "    'SELECT name FROM sqlite_master WHERE type = \"table\"')]\n",
    "print(table_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function `list_album_ids_by_letter` that takes as an argument a single character and returns a list of the primary keys of all the albums whose titles start with that character. Your function should ignore case, so that the inputs `a` and `A` yield the same results. Include error checking that raises an error in the event that the input is not a single character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_album_ids_by_letter(char):\n",
    "    if not isinstance(char, str):\n",
    "        raise TypeError('The argument must be a string')\n",
    "    if len(char) != 1:\n",
    "        raise ValueError('The argument must be a single character')\n",
    "    return [key[0] for key in c.execute(\n",
    "        f'SELECT AlbumId FROM Album WHERE Title LIKE \"{char}%\"')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [col for col in c.execute(\"PRAGMA table_info(Album)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_album_ids_by_letter('z') == [240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a function `list_song_ids_by_album_letter` that takes as an argument a single character and returns a list of the primary keys of all the songs whose album names begin with that letter. Again, your function should ignore case and perform error checking as in `list_album_ids_by_letter`. (again ignoring case). __Hint:__ You'll need a JOIN statement here. Don't forget that you can use the `cursor.description` attribute to find out about tables and the names of their columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_song_ids_by_album_letter(char):\n",
    "    if not isinstance(char, str):\n",
    "        raise TypeError('The argument must be a string')\n",
    "    if len(char) != 1:\n",
    "        raise ValueError('The argument must be a single character')\n",
    "    command = f'''SELECT TrackId FROM Track INNER JOIN Album\\\n",
    "              ON Track.AlbumId=Album.AlbumId\\\n",
    "              WHERE Title LIKE \"{char}%\"'''\n",
    "    return [key[0] for key in c.execute(command)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [col for col in c.execute(\"PRAGMA table_info(Track)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_song_ids_by_album_letter('z') == [3028, 3029, 3030, 3031,\n",
    "                                       3032, 3033, 3034, 3035,\n",
    "                                       3036, 3037]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a function `total_cost_by_album_letter` that takes as an argument a single character and returns the cost of buying every song whose album begins with that letter. This cost should be based on the tracks' unit prices, so that the cost of buying a set of tracks is simply the sum of the unit prices of all the tracks in the set. Again your function should ignore case and perform appropriate error checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost_by_album_letter(char):\n",
    "    if not isinstance(char, str):\n",
    "        raise TypeError('The argument must be a string')\n",
    "    if len(char) != 1:\n",
    "        raise ValueError('The argument must be a single character')\n",
    "    command = f'''SELECT SUM(Track.UnitPrice) AS total\\\n",
    "              FROM Track INNER JOIN Album\\\n",
    "              ON Track.AlbumId=Album.AlbumId\\\n",
    "              WHERE Title LIKE \"{char}%\"'''\n",
    "    summed = [cost[0] for cost in c.execute(command)][0]\n",
    "    if not summed:\n",
    "        summed = 0\n",
    "    return summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cost_by_album_letter('z') == 9.9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
